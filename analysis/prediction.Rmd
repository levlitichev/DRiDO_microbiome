---
title: "Prediction"
---

Table of contents:
* Predict age, all mice, genera
* Predict age, AL mice, genera
* Predict age, AL mice, species
* Predict age, AL mice, pathways
* Train on AL, predict age of DR mice, genera
* Train on AL, predict age of DR mice, pathways
* Train on 40% CR, predict age of other mice, genera
* Train on 40% CR, predict age of other mice, pathways
* Predict binary DR status, genera (with ROCs)
* Predict binary DR status, pathways (with ROCs)
* Predict DR group, genera
* Predict DR group, pathways

2024-06-27 updates:
* Added age prediction using species-level data and using all mice (instead of just AL mice)
* Switched from 70/30 train/test splits to cross-validation
* Added prediction of binary DR status (AL v. DR)

2024-10-10:
* Feature importance for DR prediction

```{r, warning=F, message=F}
library(tidyverse)
library(randomForest)
library(caret)
library(pROC) # roc function
library(foreach)
library(broom) # tidy
library(ggpubr) # stat_compare_means

age.color <- "seagreen"
diet.color <- "mediumorchid"
diet.palette <- c(AL="seashell4",
                  `1D`="skyblue",
                  `2D`="royalblue4",
                  `20`="orange",
                  `40`="firebrick")
```

# Import metadata

```{r}
stool.meta.df <- read.table(
  "../data/metadata/stool_metadata_after_QC_no_controls_n2997_240418.txt", 
  sep="\t", header=T)
mouse.meta.df <- read.csv("../data/metadata/AnimalData_Processed_20230712.csv") %>% 
  mutate(Cage=paste0("c", HID)) # create character version of cage

stool.meta.annot.df <- stool.meta.df %>%
  merge(mouse.meta.df, by.x="mouse.ID", by.y="MouseID")
```

Pre-randomization timepoints are AL.

```{r}
stool.meta.annot.df <- stool.meta.annot.df %>% 
  mutate(Diet.5mo.as.AL=case_when(
    age.wks < 25 ~ "AL",
    TRUE ~ as.character(Diet)))
```

# Import taxonomic data

## Genera

Will use relative abundances for top 100 most abundant genera.

```{r}
genus.data.df.feats.in.rows <- read.table(
  "../data/kraken_genus_relab_n100x2997.txt",
  sep="\t", header=T, row.names=1)

tax.feats <- rownames(genus.data.df.feats.in.rows)
length(tax.feats)
```

Add annotations.

```{r}
genus.annot.df <- genus.data.df.feats.in.rows %>% 
  t() %>% data.frame() %>% rownames_to_column("stool.ID") %>% 
  merge(stool.meta.annot.df, by="stool.ID")
dim(genus.annot.df)
```

## Species

Will use relative abundances for top 200 most abundant species.

```{r}
species.data.df.feats.in.rows <- read.table(
  "../data/kraken_species_relab_n200x2997.txt",
  sep="\t", header=T, row.names=1)

species.tax.feats <- rownames(species.data.df.feats.in.rows)
length(species.tax.feats)
```

Add annotations.

```{r}
species.annot.df <- species.data.df.feats.in.rows %>% 
  t() %>% data.frame() %>% rownames_to_column("stool.ID") %>% 
  merge(stool.meta.annot.df, by="stool.ID")
dim(species.annot.df)
```

# Import pathway data

Will use log2(TPM) abundances for the 272 pathways that passed prevalence filtration.

```{r}
pathway.log2tpm.df.feats.in.rows <- read.table(
  "../results/pathway_log2tpm_filt_w_comm_n273x2997.txt",
  sep="\t", header=T, quote="")
```

Exclude uniqueness and transpose to get samples in the rows.

```{r}
pathway.log2tpm.df <- pathway.log2tpm.df.feats.in.rows %>%
  dplyr::filter(feature != "Uniqueness") %>% 
  column_to_rownames("feature") %>% 
  t() %>% data.frame()

fxn.feats <- colnames(pathway.log2tpm.df)
length(fxn.feats)
```

* 272 pathways (after prevalence filtration)

Add annotations.

```{r}
pathway.log2tpm.annot.df <- pathway.log2tpm.df %>% 
  rownames_to_column("stool.ID") %>% 
  merge(stool.meta.annot.df, by="stool.ID")
dim(pathway.log2tpm.annot.df)
```

# Predict age of *all* mice (slow)

Genera, 10-fold cross validation.

Set "stool.ID" as rownames and remove extraneous columns.

```{r}
genus.data.df <- genus.annot.df %>% 
  column_to_rownames("stool.ID") %>% 
  dplyr::select(age.wks, all_of(tax.feats))
```

90% train, 10% held-out. N.B. Here we don't stratify by cage (stratification shouldn't improve prediction).

```{r}
n.folds <- 10

# shuffle IDs
set.seed(123)
shuffled.ids <- sample(rownames(genus.data.df))

# figure out how many IDs will be in each held-out group, except the last
n.per.heldout.group <- floor(length(shuffled.ids) / n.folds)

# create all but last held-out group
heldout.groups <- list()
for (ii in seq(n.folds-1)) {
  
  this.fold.ids <- shuffled.ids[
    (1 + (ii-1) * n.per.heldout.group) : (n.per.heldout.group * ii)]
  
  heldout.groups[[ii]] <- this.fold.ids
}

# last held-out group is whatever is left over
heldout.groups[[n.folds]] <- setdiff(
  rownames(genus.data.df), unlist(heldout.groups))

# # confirm that held-out groups look good
# length(unlist(heldout.groups)) # 2997
# vapply(heldout.groups, FUN=length, FUN.VALUE=1) # all 299 except last one is 306
```

Run RF on each fold (takes ~5 min).

```{r}
set.seed(456)
pred.v.obs.df.age.genus.cv <- foreach(
  this.heldout.group = heldout.groups,
  .combine="rbind") %do% {
    
    this.test.ids <- this.heldout.group
    this.train.ids <- setdiff(rownames(genus.data.df), this.test.ids)
    
    this.train.df <- genus.data.df[this.train.ids, ]
    this.test.df <- genus.data.df[this.test.ids, ]
    
    this.age.genus.rf.res <- randomForest(
      age.wks ~ .,
      data = this.train.df)
    
    out.preds.df <- data.frame(
      pred = predict(this.age.genus.rf.res, newdata=this.test.df),
      obs = this.test.df$age.wks
    )
    
    return(out.preds.df)
    
  }
```

```{r}
MAE.age.pred.all.samples.genus.cv <- pred.v.obs.df.age.genus.cv %>% 
  mutate(pred.minus.obs = pred - obs) %>% 
  pull(pred.minus.obs) %>% abs() %>% mean()

pred.v.obs.df.age.genus.cv %>% 
  mutate(pred.minus.obs = pred - obs) %>% 
  summarise(mae = mean(abs(pred.minus.obs)),
            sd = sd(abs(pred.minus.obs)))
```

* MAE (10-fold cross validation) = 17.4 ± 15.4 weeks

```{r}
(age.prediction.cv.p <- pred.v.obs.df.age.genus.cv %>% {
  ggplot(., aes(x=obs*0.23, y=pred*0.23)) +
    geom_jitter(width=0.25, shape=16, color=age.color) +
    geom_smooth(method="lm", linewidth=0.5, color=age.color) +
    geom_abline(slope=1, lty=2) +
    labs(x="Actual age (months)", y="Predicted age (months)",
         title=sprintf("Age prediction, all samples; MAE = %.2f weeks", MAE.age.pred.all.samples.genus.cv)) +
    theme_classic(base_size=8) +
    theme(legend.position="none")
})
```

```{r}
pdf("../plots/age_prediction_all_mice_10_fold_cv.pdf", width=2, height=2)
age.prediction.cv.p
dev.off()
```


# Predict age of AL mice

## Genera

```{r}
genus.AL.annot.df <- genus.annot.df %>% 
  dplyr::filter(Diet == "AL")
```

Set "stool.ID" as rownames and remove extraneous columns.

```{r}
genus.AL.data.df <- genus.AL.annot.df %>% 
  column_to_rownames("stool.ID") %>% 
  dplyr::select(age.wks, all_of(tax.feats))
```

10-fold cross validation: 90% train, 10% held-out. N.B. Here we don't stratify by cage (stratification shouldn't improve prediction).

```{r}
n.folds <- 10

# shuffle IDs
set.seed(123)
AL.shuffled.ids <- sample(rownames(genus.AL.data.df))

# figure out how many IDs will be in each held-out group, except the last
AL.n.per.heldout.group <- floor(length(AL.shuffled.ids) / n.folds)

# create all but last held-out group
AL.heldout.groups <- list()
for (ii in seq(n.folds-1)) {
  
  this.fold.ids <- AL.shuffled.ids[
    (1 + (ii-1) * AL.n.per.heldout.group) : (AL.n.per.heldout.group * ii)]
  
  AL.heldout.groups[[ii]] <- this.fold.ids
}

# last held-out group is whatever is left over
AL.heldout.groups[[n.folds]] <- setdiff(
  rownames(genus.AL.data.df), unlist(AL.heldout.groups))

# confirm that held-out groups look good
# length(unlist(AL.heldout.groups)) # 573
# vapply(AL.heldout.groups, FUN=length, FUN.VALUE=1) # all 57 except last one is 60
```

Run RF on each fold.

```{r}
set.seed(456)
pred.v.obs.df.age.AL.genus.cv <- foreach(
  this.heldout.group = AL.heldout.groups,
  .combine="rbind") %do% {
    
    this.test.ids <- this.heldout.group
    this.train.ids <- setdiff(rownames(genus.AL.data.df), this.test.ids)
    
    this.train.df <- genus.AL.data.df[this.train.ids, ]
    this.test.df <- genus.AL.data.df[this.test.ids, ]
    
    this.age.genus.AL.rf.res <- randomForest(
      age.wks ~ .,
      data = this.train.df)
    
    out.preds.df <- data.frame(
      pred = predict(this.age.genus.AL.rf.res, newdata=this.test.df),
      obs = this.test.df$age.wks
    )
    
    return(out.preds.df)
    
  }
```

```{r}
MAE.age.pred.AL.genus.cv <- pred.v.obs.df.age.AL.genus.cv %>% 
  mutate(pred.minus.obs = pred - obs) %>% 
  pull(pred.minus.obs) %>% abs() %>% mean()

pred.v.obs.df.age.AL.genus.cv %>% 
  mutate(pred.minus.obs = pred - obs) %>% 
  summarise(mae = mean(abs(pred.minus.obs)),
            sd = sd(abs(pred.minus.obs)))
```

* MAE (10-fold cross validation) = 16.3 ± 13.2 weeks

```{r}
(age.prediction.AL.cv.p <- pred.v.obs.df.age.AL.genus.cv %>% {
  ggplot(., aes(x=obs*0.23, y=pred*0.23)) +
    geom_jitter(width=0.25, shape=16, color=age.color) +
    geom_smooth(method="lm", linewidth=0.5, color=age.color) +
    geom_abline(slope=1, lty=2) +
    labs(x="Actual age (months)", y="Predicted age (months)",
         title=sprintf("Age prediction, DO AL; MAE= %.2f weeks",
                       MAE.age.pred.AL.genus.cv)) +
    theme_classic(base_size=8) +
    theme(legend.position="none")
})
```

```{r}
pdf("../plots/age_prediction_AL_10_fold_cv.pdf", width=2, height=2)
age.prediction.AL.cv.p
dev.off()
```

### Feature importance

Ugly to repeat random forest training just to get feature importance, but here we are.

```{r}
set.seed(456)
feat.imp.df.age.AL.genus.cv <- foreach(
  this.heldout.group = AL.heldout.groups,
  .combine="rbind") %do% {
    
    this.test.ids <- this.heldout.group
    this.train.ids <- setdiff(rownames(genus.AL.data.df), this.test.ids)
    
    this.train.df <- genus.AL.data.df[this.train.ids, ]
    this.test.df <- genus.AL.data.df[this.test.ids, ]
    
    this.age.genus.AL.rf.res <- randomForest(
      age.wks ~ .,
      data = this.train.df,
      importance = T)
    
    feat.imp.df <- data.frame(this.age.genus.AL.rf.res$importance) %>% 
      rownames_to_column("feature")
    
    return(feat.imp.df)
    
  }
```


```{r}
feat.imp.summarised.df.age.AL.genus.cv <- feat.imp.df.age.AL.genus.cv %>% 
  group_by(feature) %>% 
  summarise(mean.perc.inc.MSE = mean(X.IncMSE), .groups="drop") %>% 
  arrange(desc(mean.perc.inc.MSE))

age.pred.top.10.most.imp.feats <- feat.imp.summarised.df.age.AL.genus.cv %>% 
  slice_max(mean.perc.inc.MSE, n=10) %>% 
  pull(feature)
```

```{r}
(age.pred.feat.imp.p <- feat.imp.df.age.AL.genus.cv %>% 
   dplyr::filter(feature %in% age.pred.top.10.most.imp.feats) %>% 
   ggplot(aes(x=X.IncMSE, y=reorder(feature, X.IncMSE))) +
   stat_summary(fun="mean", geom="col", fill=age.color) +
   geom_jitter(height=0.2, shape=16) +
   labs(x="% increase in MSE", y="Genus",
        title="10 most important genera for age prediction") +
   theme_classic(base_size=8))
```

```{r}
pdf("../plots/age_pred_top_10_most_imp_feats.pdf", height=2, width=3)
age.pred.feat.imp.p
dev.off()
```

## Species

```{r}
species.AL.annot.df <- species.annot.df %>% 
  dplyr::filter(Diet == "AL")
```

Set "stool.ID" as rownames and remove extraneous columns.

```{r}
species.AL.data.df <- species.AL.annot.df %>% 
  column_to_rownames("stool.ID") %>% 
  dplyr::select(age.wks, all_of(species.tax.feats))
```

10-fold cross validation: 90% train, 10% held-out. Use the same held-out cages as for genus prediction.

Run RF on each fold.

```{r}
set.seed(456)
pred.v.obs.df.age.AL.species.cv <- foreach(
  this.heldout.group = AL.heldout.groups,
  .combine="rbind") %do% {
    
    this.test.ids <- this.heldout.group
    this.train.ids <- setdiff(rownames(species.AL.data.df), this.test.ids)
    
    this.train.df <- species.AL.data.df[this.train.ids, ]
    this.test.df <- species.AL.data.df[this.test.ids, ]
    
    this.age.species.AL.rf.res <- randomForest(
      age.wks ~ .,
      data = this.train.df)
    
    out.preds.df <- data.frame(
      pred = predict(this.age.species.AL.rf.res, newdata=this.test.df),
      obs = this.test.df$age.wks
    )
    
    return(out.preds.df)
    
  }
```

```{r}
MAE.age.pred.AL.species.cv <- pred.v.obs.df.age.AL.species.cv %>% 
  mutate(pred.minus.obs = pred - obs) %>% 
  pull(pred.minus.obs) %>% abs() %>% mean()

pred.v.obs.df.age.AL.species.cv %>% 
  mutate(pred.minus.obs = pred - obs) %>% 
  summarise(mae = mean(abs(pred.minus.obs)),
            sd = sd(abs(pred.minus.obs)))
```

* MAE (10-fold cross validation) = 13.8 ± 11.4 weeks

```{r}
(age.prediction.AL.species.cv.p <- pred.v.obs.df.age.AL.species.cv %>% {
  ggplot(., aes(x=obs*0.23, y=pred*0.23)) +
    geom_jitter(width=0.25, shape=16, color=age.color) +
    geom_smooth(method="lm", linewidth=0.5, color=age.color) +
    geom_abline(slope=1, lty=2) +
    labs(x="Actual age (months)", y="Predicted age (months)",
         title=sprintf("Age prediction, DO AL, species-level relabs; MAE = %.2f weeks", MAE.age.pred.AL.species.cv)) +
    theme_classic(base_size=8) +
    theme(legend.position="none")
})
```

* With 10-fold cross-validation, performance looks a lot better for B6 mice

```{r}
pdf("../plots/age_prediction_AL_species_10_fold_cv.pdf", width=2, height=2)
age.prediction.AL.species.cv.p
dev.off()
```

## Pathways

```{r}
pathway.log2tpm.AL.annot.df <- pathway.log2tpm.annot.df %>% 
  dplyr::filter(Diet == "AL")
```

Set "stool.ID" as rownames and remove extraneous columns.

```{r}
pathway.log2tpm.AL.data.df <- pathway.log2tpm.AL.annot.df %>% 
  column_to_rownames("stool.ID") %>% 
  dplyr::select(age.wks, all_of(fxn.feats))
```

10-fold cross validation: 90% train, 10% held-out. Use the same held-out cages as for genus prediction.

Run RF on each fold.

```{r}
set.seed(456)
pred.v.obs.df.age.AL.pathways.cv <- foreach(
  this.heldout.group = AL.heldout.groups,
  .combine="rbind") %do% {
    
    this.test.ids <- this.heldout.group
    this.train.ids <- setdiff(rownames(pathway.log2tpm.AL.data.df), this.test.ids)
    
    this.train.df <- pathway.log2tpm.AL.data.df[this.train.ids, ]
    this.test.df <- pathway.log2tpm.AL.data.df[this.test.ids, ]
    
    this.age.pathway.AL.rf.res <- randomForest(
      age.wks ~ .,
      data = this.train.df)
    
    out.preds.df <- data.frame(
      pred = predict(this.age.pathway.AL.rf.res, newdata=this.test.df),
      obs = this.test.df$age.wks
    )
    
    return(out.preds.df)
    
  }
```

```{r}
MAE.age.pred.AL.pathways.cv <- pred.v.obs.df.age.AL.pathways.cv %>% 
  mutate(pred.minus.obs = pred - obs) %>% 
  pull(pred.minus.obs) %>% abs() %>% mean()

pred.v.obs.df.age.AL.pathways.cv %>% 
  mutate(pred.minus.obs = pred - obs) %>% 
  summarise(mae = mean(abs(pred.minus.obs)),
            sd = sd(abs(pred.minus.obs)))
```

* Pathway MAE (10-fold cross validation) = 21.9 ± 15.8 weeks
* Not as good as prediction using taxonomic features

```{r}
(age.prediction.AL.pathways.cv.p <- pred.v.obs.df.age.AL.pathways.cv %>% {
  ggplot(., aes(x=obs*0.23, y=pred*0.23)) +
    geom_jitter(width=0.25, shape=16, color=age.color) +
    geom_smooth(method="lm", linewidth=0.5, color=age.color) +
    geom_abline(slope=1, lty=2) +
    labs(x="Actual age (months)", y="Predicted age (months)",
         title=sprintf("Age prediction, AL, pathways; MAE = %.2f weeks", MAE.age.pred.AL.pathways.cv)) +
    theme_classic(base_size=8) +
    theme(legend.position="none")
})
```


```{r}
pdf("../plots/age_prediction_AL_pathways_10_fold_cv.pdf", width=2, height=2)
age.prediction.AL.pathways.cv.p
dev.off()
```

### Feature importance

```{r}
set.seed(456)
feat.imp.df.age.AL.pathways.cv <- foreach(
  this.heldout.group = AL.heldout.groups,
  .combine="rbind") %do% {
    
    this.test.ids <- this.heldout.group
    this.train.ids <- setdiff(rownames(pathway.log2tpm.AL.data.df), this.test.ids)
    
    this.train.df <- pathway.log2tpm.AL.data.df[this.train.ids, ]
    this.test.df <- pathway.log2tpm.AL.data.df[this.test.ids, ]
    
    this.age.pathway.AL.rf.res <- randomForest(
      age.wks ~ .,
      data = this.train.df,
      importance = T)
    
    feat.imp.df <- data.frame(this.age.pathway.AL.rf.res$importance) %>% 
      rownames_to_column("feature")
    
    return(feat.imp.df)
    
  }
```

```{r}
feat.imp.summarised.df.age.AL.pathways.cv <- feat.imp.df.age.AL.pathways.cv %>% 
  group_by(feature) %>% 
  summarise(mean.perc.inc.MSE = mean(X.IncMSE), .groups="drop") %>% 
  arrange(desc(mean.perc.inc.MSE))

age.pred.top.10.most.imp.pathways <- feat.imp.summarised.df.age.AL.pathways.cv %>% 
  slice_max(mean.perc.inc.MSE, n=10) %>% 
  pull(feature)
```

```{r}
(age.pred.pathways.feat.imp.p <- feat.imp.df.age.AL.pathways.cv %>% 
   dplyr::filter(feature %in% age.pred.top.10.most.imp.pathways) %>% 
   
   # use human-readable pathway name, but make the label small
   merge(pathway.names.df, by.x="feature", by.y="short.clean") %>% 
   
   ggplot(aes(x=X.IncMSE, y=reorder(after.colon.short.w.ID, X.IncMSE))) +
   stat_summary(fun="mean", geom="col", fill=age.color) +
   geom_jitter(height=0.2, shape=16) +
   labs(x="% increase in MSE", y="Pathway",
        title="10 most important pathways for age prediction") +
   theme(axis.text.y = element_text(size=4)))
```

```{r}
pdf("../plots/age_pred_top_10_most_imp_pathways.pdf", height=2, width=3)
age.pred.pathways.feat.imp.p
dev.off()
```

# Train on AL, predict age for DR

## Genera

```{r}
genus.AL.data.df.w.age <- genus.AL.annot.df %>% 
  
  # keep just age and microbiome features
  dplyr::select(age.wks, all_of(tax.feats))
```

```{r}
rf.age.AL.genus <- randomForest(
  age.wks ~ .,
  data=genus.AL.data.df.w.age,
  importance=T)
```

```{r}
# subset to DR samples
genus.DR.annot.df <- genus.annot.df %>% 
  dplyr::filter(Diet != "AL")

# keep just microbiome features
genus.DR.data.df <- genus.DR.annot.df %>% dplyr::select(all_of(tax.feats))
dim(genus.DR.data.df)
```

Predictions on DR.

```{r}
age.preds.on.DR.trained.on.AL <- predict(
  object = rf.age.AL.genus, 
  newdata = genus.DR.data.df)

DR.pred.df <- data.frame(
  pred = age.preds.on.DR.trained.on.AL,
  obs = genus.DR.annot.df$age.wks,
  Diet = genus.DR.annot.df$Diet
)
```

Predictions on AL -- use OOB preds.

```{r}
AL.pred.df <- data.frame(
  pred = rf.age.AL.genus$predicted, 
  obs = genus.AL.annot.df$age.wks,
  Diet = "AL")
```

Compare DR predictions to AL predictions.

```{r}
pred.v.obs.df.DR.and.AL <- rbind(AL.pred.df, DR.pred.df) %>% 
  mutate(is.AL = (Diet == "AL")) %>% 
  mutate(age.approx.wks = case_when(
    obs %in% c(20, 21, 22, 23) ~ 21,
    obs %in% c(35, 38) ~ 35,
    obs %in% c(43, 44) ~ 44,
    obs %in% c(68, 69) ~ 69,
    obs %in% c(95, 96, 97) ~ 96,
    obs %in% c(120, 121, 122) ~ 121,
    obs %in% c(148, 149) ~ 148,
    obs %in% c(172, 173, 174, 175) ~ 174,
    obs %in% c(200, 201, 203) ~ 200)) %>% 
  mutate(age.approx.months = round(age.approx.wks/4.34)) %>% 
  mutate(pred.minus.obs = pred - obs)
```

Compute t-test between AL and DR predictions at each age.

```{r}
DR.v.AL.pred.t.test.per.age.pval.df <- pred.v.obs.df.DR.and.AL %>% 
  dplyr::filter(age.approx.months %in% c(5, 10, 16, 22, 28)) %>%
  group_by(age.approx.months) %>%
  do(tidy(t.test(pred ~ is.AL, data=.))) %>%
  ungroup() %>% 
  dplyr::select(age.approx.months, p.value) %>% 
  mutate(t.test.pval.symbol = case_when(
    p.value < 0.0001 ~ "****",
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    TRUE ~ "ns"))
```

```{r}
(AL.v.DR.age.preds.p <- pred.v.obs.df.DR.and.AL %>% 
   arrange(is.AL) %>% 
   dplyr::filter(age.approx.months %in% c(5, 10, 16, 22, 28)) %>% 
   ggplot(aes(x=obs/4.34, y=pred/4.34, color=is.AL)) +
   geom_abline(slope=1, lty=2) +
   geom_vline(xintercept=6, lty=2) +
   geom_text(aes(x=age.approx.months, y=30, label=t.test.pval.symbol, color=NULL), 
             size=0.36*6, data=DR.v.AL.pred.t.test.per.age.pval.df) +
   geom_jitter(width=0.5, shape=16, size=0.5) +
   stat_summary(aes(x=age.approx.months, group=is.AL), fun="mean", geom="crossbar", width=3) +
   labs(x="Actual age (months)", y="Predicted age (months)", 
        color="Dietary group", title="Taxonomic features") +
   scale_color_manual(values = c(`TRUE`="seashell4", `FALSE`=diet.color)) +
   theme_classic(base_size=8) +
   theme(legend.position="none"))
```

* We consistently predict *higher* age for DR samples
* Why do we predict higher age at 5 months? Because OOB accuracy will be a little better than testing on never before seen samples. Therefore, the AL samples will be closer to y=x.

```{r}
pdf("../plots/age_prediction_DR_trained_on_AL.pdf", width=2, height=2)
AL.v.DR.age.preds.p
dev.off()
```

## Pathways

Train on AL samples now.

```{r}
pathway.log2tpm.AL.data.df.w.age <- pathway.log2tpm.AL.annot.df %>% 
  dplyr::select(age.wks, all_of(fxn.feats)) # keep just age and microbiome features
```

```{r}
rf.age.AL.pathway <- randomForest(
  age.wks ~ .,
  data=pathway.log2tpm.AL.data.df.w.age,
  importance=T)
```

```{r}
# subset to DR samples
pathway.log2tpm.DR.annot.df <- pathway.log2tpm.annot.df %>% 
  dplyr::filter(Diet != "AL")

# keep just microbiome features
pathway.log2tpm.DR.data.df <- pathway.log2tpm.DR.annot.df %>% 
  dplyr::select(all_of(fxn.feats))
dim(pathway.log2tpm.DR.data.df)
```

Predictions on DR.

```{r}
age.preds.on.DR.trained.on.AL.pathways <- predict(
  object = rf.age.AL.pathway, 
  newdata = pathway.log2tpm.DR.data.df)

pathway.DR.pred.df <- data.frame(
  pred = age.preds.on.DR.trained.on.AL.pathways,
  obs = pathway.log2tpm.DR.annot.df$age.wks,
  Diet = pathway.log2tpm.DR.annot.df$Diet
)
```

Predictions on AL -- use OOB preds.

```{r}
pathway.AL.pred.df <- data.frame(
  pred = rf.age.AL.pathway$predicted, 
  obs = pathway.log2tpm.AL.annot.df$age.wks,
  Diet = "AL")
```

Compare DR predictions to AL predictions.

```{r}
pred.v.obs.df.DR.and.AL.pathway <- rbind(pathway.AL.pred.df, pathway.DR.pred.df) %>% 
  mutate(is.AL = (Diet == "AL")) %>% 
  mutate(age.approx.wks = case_when(
    obs %in% c(20, 21, 22, 23) ~ 21,
    obs %in% c(35, 38) ~ 35,
    obs %in% c(43, 44) ~ 44,
    obs %in% c(68, 69) ~ 69,
    obs %in% c(95, 96, 97) ~ 96,
    obs %in% c(120, 121, 122) ~ 121,
    obs %in% c(148, 149) ~ 148,
    obs %in% c(172, 173, 174, 175) ~ 174,
    obs %in% c(200, 201, 203) ~ 200)) %>% 
  mutate(age.approx.months = round(age.approx.wks/4.34)) %>% 
  mutate(pred.minus.obs = pred - obs)
```

Compute t-test between AL and DR predictions at each age.

```{r}
pathway.DR.v.AL.pred.t.test.per.age.pval.df <- pred.v.obs.df.DR.and.AL.pathway %>% 
  dplyr::filter(age.approx.months %in% c(5, 10, 16, 22, 28)) %>%
  group_by(age.approx.months) %>%
  do(tidy(t.test(pred ~ is.AL, data=.))) %>%
  ungroup() %>% 
  dplyr::select(age.approx.months, p.value) %>% 
  mutate(t.test.pval.symbol = case_when(
    p.value < 0.0001 ~ "****",
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    TRUE ~ "ns"))
```

```{r}
(AL.v.DR.age.preds.pathway.p <- pred.v.obs.df.DR.and.AL.pathway %>% 
   arrange(is.AL) %>% 
   dplyr::filter(age.approx.months %in% c(5, 10, 16, 22, 28)) %>% 
   ggplot(aes(x=obs/4.34, y=pred/4.34, color=is.AL)) +
   geom_abline(slope=1, lty=2) +
   geom_vline(xintercept=6, lty=2) +
   geom_text(aes(x=age.approx.months, y=28, label=t.test.pval.symbol, color=NULL), 
             size=0.36*6, data=pathway.DR.v.AL.pred.t.test.per.age.pval.df) +
   geom_jitter(width=0.5, shape=16, size=0.5) +
   stat_summary(aes(x=age.approx.months, group=is.AL), fun="mean", geom="crossbar", width=3) +
   # geom_smooth(se=F) +
   labs(x="Actual age (months)", y="Predicted age (months)", 
        color="Dietary group", title="Functional features") +
   scale_color_manual(values = c(`TRUE`="seashell4", `FALSE`=diet.color)) +
   theme_classic(base_size=8) +
   theme(legend.position="none"))
```

```{r}
pdf("../plots/age_prediction_DR_trained_on_AL_pathways.pdf", width=2, height=2)
AL.v.DR.age.preds.pathway.p
dev.off()
```

# Train on 40% CR, predict age for rest

## Genera

```{r}
genus.40.annot.df <- genus.annot.df %>% 
  dplyr::filter(Diet == "40")

genus.not40.annot.df <- genus.annot.df %>% 
  dplyr::filter(Diet != "40")
```

```{r}
genus.40.data.df.w.age <- genus.40.annot.df %>% 
  dplyr::select(age.wks, all_of(tax.feats)) # keep just age and microbiome features

genus.not40.data.df.w.age <- genus.not40.annot.df %>% 
  dplyr::select(age.wks, all_of(tax.feats)) # keep just age and microbiome features

dim(genus.40.data.df.w.age)
dim(genus.not40.data.df.w.age)
```

```{r}
rf.age.40.genus <- randomForest(
  age.wks ~ .,
  data=genus.40.data.df.w.age,
  importance=T)
```

```{r}
age.preds.trained.on.40 <- predict(
  object = rf.age.40.genus, 
  newdata = genus.not40.data.df.w.age)

genus.not40.annot.df.w.preds.trained.on.40 <- genus.not40.annot.df %>% 
  mutate(pred = age.preds.trained.on.40) %>% 
  mutate(actual.minus.pred = age.wks - pred)
```

```{r}
(train.40.test.rest.genus.p <- genus.not40.annot.df.w.preds.trained.on.40 %>% 
   dplyr::filter(age.approx.months %in% c(5, 10, 16, 22, 28)) %>%
   mutate(Diet = factor(Diet, levels = c("AL", "1D", "2D", "20"))) %>% 
   ggplot(aes(x=Diet, y=pred*0.23, fill=Diet)) +
   geom_boxplot(outlier.shape=16, outlier.size=0.5, linewidth=0.5) +
   geom_hline(aes(yintercept = age.approx.months), lty=2, linewidth=0.5) +
   facet_wrap(~age.approx.months, nrow=1) +
   stat_compare_means(method="t.test", label="p.signif", ref.group="AL") +
   labs(x="", y="Predicted age (months)", title="Trained on 40%, dotted line shows actual age") +
   scale_fill_manual(values=diet.palette) +
   theme_classic(base_size=8) +
   theme(legend.position="none"))
```

```{r}
pdf("../plots/age_prediction_genera_trained_on_40_boxplots.pdf", height=1.5, width=4)
train.40.test.rest.genus.p
dev.off()
```

## Pathways

```{r}
pathway.40.log2tpm.annot.df <- pathway.log2tpm.annot.df %>% 
  dplyr::filter(Diet == "40")

pathway.not40.log2tpm.annot.df <- pathway.log2tpm.annot.df %>% 
  dplyr::filter(Diet != "40")
```

```{r}
pathway.40.data.df.w.age <- pathway.40.log2tpm.annot.df %>% 
  dplyr::select(age.wks, all_of(fxn.feats)) # keep just age and microbiome features

pathway.not40.data.df.w.age <- pathway.not40.log2tpm.annot.df %>% 
  dplyr::select(age.wks, all_of(fxn.feats)) # keep just age and microbiome features

dim(pathway.40.data.df.w.age)
dim(pathway.not40.data.df.w.age)
```

```{r}
rf.age.40.pathway <- randomForest(
  age.wks ~ .,
  data=pathway.40.data.df.w.age,
  importance=T)
```

```{r}
age.preds.trained.on.40.pathway <- predict(
  object = rf.age.40.pathway, 
  newdata = pathway.not40.data.df.w.age)

pathway.annot.df.w.preds.trained.on.40 <- pathway.not40.log2tpm.annot.df %>% 
  mutate(pred = age.preds.trained.on.40.pathway) %>% 
  mutate(actual.minus.pred = age.wks - pred)
```

```{r}
(train.40.test.rest.pathway.p <- pathway.annot.df.w.preds.trained.on.40 %>% 
   dplyr::filter(age.approx.months %in% c(5, 10, 16, 22, 28)) %>%
   mutate(Diet = factor(Diet, levels = c("AL", "1D", "2D", "20"))) %>% 
   ggplot(aes(x=Diet, y=pred*0.23, fill=Diet)) +
   geom_boxplot(outlier.shape=16, outlier.size=0.5, linewidth=0.5) +
   geom_hline(aes(yintercept = age.approx.months), lty=2, linewidth=0.5) +
   facet_wrap(~age.approx.months, nrow=1) +
   stat_compare_means(method="t.test", label="p.signif", ref.group="AL") +
   labs(x="", y="Predicted age (months)", title="Trained on 40%, dotted line shows actual age") +
   scale_fill_manual(values=diet.palette) +
   theme_classic(base_size=8) +
   theme(legend.position="none"))
```

```{r}
pdf("../plots/age_prediction_pathways_trained_on_40_boxplots.pdf", height=1.5, width=4)
train.40.test.rest.pathway.p
dev.off()
```

# Define functions related to DR prediction

Perform 5-fold cross-validation while stratifying by cage, i.e. each cage is only present in training or testing, not both. Stratifying by cage is important for prediction of DR because the classifier could theoretically achieve good performance simply by learning which mice live together, rather than learning the signature of a particular DR.

```{r}
get_list_of_heldout_cages_per_fold <- function(this.annot.df, n.folds=5) {
  
  # shuffle cages
  cage.shuffled.vec <- sample(unique(this.annot.df$Cage))
  
  # figure out how many cages will be in each held-out group, except the last
  cages.per.heldout.group <- floor(length(cage.shuffled.vec) / n.folds)
  
  # create all but last held-out group
  list.of.heldout.cages <- list()
  for (ii in seq(n.folds-1)) {
    
    this.fold.cages <- cage.shuffled.vec[
      (1 + (ii-1) * cages.per.heldout.group) : (cages.per.heldout.group * ii)]
    
    list.of.heldout.cages[[ii]] <- this.fold.cages
  }
  
  # length(list.of.heldout.cages[[1]])
  
  # last held-out group is whatever is left over
  list.of.heldout.cages[[n.folds]] <- setdiff(
    cage.shuffled.vec, unlist(list.of.heldout.cages))
  
  return(list.of.heldout.cages)
  
  # confirm that held-out groups look good
  # length(cage.shuffled.vec)
  # length(unlist(list.of.heldout.cages)) 
  # vapply(list.of.heldout.cages, FUN=length, FUN.VALUE=1)
  
}
```

Performing binary DR prediction (yes or no) within a single fold and producing coordinates for an ROC.

```{r}
run_DR_pred_per_fold <- function(this.annot.df, heldout.cages.vec, tax.feats) {
  
  this.test.ids <- this.annot.df %>% 
    dplyr::filter(Cage %in% heldout.cages.vec) %>% 
    pull(stool.ID)
  this.train.ids <- setdiff(this.annot.df$stool.ID, this.test.ids)
  # length(this.test.ids)
  # length(this.train.ids)
  
  this.train.df <- this.annot.df %>% 
    dplyr::filter(stool.ID %in% this.train.ids) %>% 
    dplyr::select(DR, all_of(tax.feats))
  this.test.df <- this.annot.df %>% 
    dplyr::filter(stool.ID %in% this.test.ids) %>% 
    dplyr::select(DR, all_of(tax.feats))
  
  this.rf.res <- randomForest(
    DR ~ .,
    data = this.train.df)
  
  # evaluate on test data
  this.DR.pred.scores <- predict(this.rf.res, this.test.df, type="prob") %>% 
    data.frame() %>% 
    pull(Y)
  
  # calculate ROC coordinates and AUC
  this.roc.res <- roc(this.test.df$DR, this.DR.pred.scores,
                      levels=c("N", "Y"), direction="<")
  this.roc.coord.df <- coords(this.roc.res)
  this.auc <- as.numeric(auc(this.roc.res))
  
  # add AUC as new column
  out.df <- this.roc.coord.df %>% 
    mutate(AUC = this.auc)
  
  return(out.df)
  
}
```

Run binary DR prediction across folds and extract ROC coordinates for each fold.

```{r}
get_roc_coord_for_DR_pred_per_age <- function(this.age, this.annot.df, tax.feats) {
  
  # subset to this age
  this.age.annot.df <- this.annot.df %>% 
    dplyr::filter(age.approx.months == this.age)
  
  # perform cross-validation, stratifying by cage
  # return which cages are held out in each fold
  this.age.list.of.heldout.cages.per.fold <- get_list_of_heldout_cages_per_fold(this.age.annot.df)
  
  # get ROC coords within each fold
  this.age.roc.coord.df.cv.strat.by.cage <- foreach(
    this.fold.ii = seq(length(this.age.list.of.heldout.cages.per.fold)),
    .combine="rbind") %do% {
      
      roc.df <- run_DR_pred_per_fold(
        this.age.annot.df, 
        this.age.list.of.heldout.cages.per.fold[[this.fold.ii]],
        tax.feats)
      
      # add fold and age
      roc.df$fold <- this.fold.ii
      roc.df$age <- this.age
      
      return(roc.df)
      
    }
  
  return(this.age.roc.coord.df.cv.strat.by.cage)
  
}
```

Convert the default ROC coordinates into a format that will make it easy to calculate mean ROC.

1. Create a vector of evenly spaced x-values for 0 to 1
2. For each x, identify the largest 1-minus-specificity value that is less than or equal to x (`largest.1.minus.spec.lteq.x`)
3. For each `largest.1.minus.spec.lteq.x` value, get all corresponding sensitivity values and return the maximum

```{r}
create_roc_plot_df <- function(roc_coord_df) {
  
  # create list of evenly spaced x coordinates
  x <- seq(from=0, to=1, length=1000)
  
  # for each x, identify the largest 1-minus-specificity value that is less than or equal to x
  largest.1.minus.spec.lteq.x <- vapply(
    x,
    FUN=function(one.x) {roc_coord_df %>% dplyr::filter(one.minus.spec <= one.x) %>% pull(one.minus.spec) %>% max()},
    FUN.VALUE=1)
  
  # for each of these 1-minus-specificity values, get the maximum corresponding sensitivity
  interpolated.sensitivity <- vapply(
    largest.1.minus.spec.lteq.x,
    FUN=function(one.1.minus.spec) {roc_coord_df %>% dplyr::filter(one.minus.spec == one.1.minus.spec) %>% pull(sensitivity) %>% max()},
    FUN.VALUE=1)
  
  # should always start at x=0, y=0 and end at x=1, y=1
  interpolated.sensitivity[1] <- 0
  interpolated.sensitivity[length(interpolated.sensitivity)] <- 1
  
  out.df <- data.frame(
    x = x,
    y = interpolated.sensitivity)
  
  return(out.df)
  
}
```

# Predict binary DR (with ROCs)

## Genera

Convert Diet to (binary) DR column.

```{r}
genus.annot.df <- genus.annot.df %>% 
  mutate(DR = factor(case_when(
    Diet == "AL" ~ "N",
    TRUE ~ "Y")))

table(genus.annot.df$DR)
```

* 573 AL samples, 2424 DR samples

Perform prediction within each age. Return ROC coordinates for each fold.

```{r}
set.seed(456)
DR.pred.roc.coords.5mo <- get_roc_coord_for_DR_pred_per_age(5, genus.annot.df, tax.feats)
DR.pred.roc.coords.10mo <- get_roc_coord_for_DR_pred_per_age(10, genus.annot.df, tax.feats)
DR.pred.roc.coords.16mo <- get_roc_coord_for_DR_pred_per_age(16, genus.annot.df, tax.feats)
DR.pred.roc.coords.22mo <- get_roc_coord_for_DR_pred_per_age(22, genus.annot.df, tax.feats)
DR.pred.roc.coords.28mo <- get_roc_coord_for_DR_pred_per_age(28, genus.annot.df, tax.feats)

DR.pred.roc.coord.df.cv.strat.by.cage <- rbind(
  DR.pred.roc.coords.5mo,
  DR.pred.roc.coords.10mo,
  DR.pred.roc.coords.16mo,
  DR.pred.roc.coords.22mo,
  DR.pred.roc.coords.28mo)

table(DR.pred.roc.coord.df.cv.strat.by.cage$age)
```

Create one minus specificity column because that's what we actually plot.

```{r}
DR.pred.roc.coord.df.cv.strat.by.cage <- DR.pred.roc.coord.df.cv.strat.by.cage %>%
  mutate(one.minus.spec = 1-specificity)
```

Create interpolated ROCs to make it easy to create a mean ROC.

```{r}
# takes ~15 seconds
DR.pred.roc.plot.df.cv.strat.by.cage <- DR.pred.roc.coord.df.cv.strat.by.cage %>% 
  group_by(age, fold, AUC) %>% 
  group_modify(~ create_roc_plot_df(.x)) %>% 
  ungroup()
```

Calculate mean AUC per age.

```{r}
DR.pred.mean.AUC.per.age.cv.strat.by.cage <- DR.pred.roc.plot.df.cv.strat.by.cage %>% 
  distinct(age, fold, AUC) %>%
  group_by(age) %>% 
  summarise(mean.AUC = mean(AUC), .groups="drop")
```

Create mean ROC.

```{r}
DR.pred.mean.roc.plot.df.cv.strat.by.cage <- DR.pred.roc.plot.df.cv.strat.by.cage %>% 
  
  group_by(age, x) %>% 
  summarise(y = mean(y), .groups="drop") %>% 
  
  # add mean AUC (helpful for plotting)
  left_join(DR.pred.mean.AUC.per.age.cv.strat.by.cage, by="age") %>% 
  
  # make it pretty 
  mutate(mean.AUC.str = sprintf("Mean AUC = %.2f", mean.AUC))
```

Plot!

```{r}
(DR.pred.roc.curves.cv.strat.by.cage <- DR.pred.roc.plot.df.cv.strat.by.cage %>% 
   
   # add mean AUC per age
   left_join(DR.pred.mean.AUC.per.age.cv.strat.by.cage, by="age") %>% 
   
   # make it pretty
   mutate(mean.AUC.str = sprintf("Mean AUC = %.2f", mean.AUC)) %>% 
   
   arrange(fold) %>% 
   
   ggplot(aes(x=x, y=y, group=fold)) +
   geom_abline(slope=1, lty=2) +
   geom_path(alpha=0.3) +
   geom_path(aes(group=NULL), linewidth=1, color=diet.color,
             data=DR.pred.mean.roc.plot.df.cv.strat.by.cage) +
   theme_classic(base_size=8) +
   labs(x="1 - Specificity", y="Sensitivity") +
   facet_wrap(~ age + mean.AUC.str, nrow=1) +
   scale_x_continuous(breaks=c(0, 0.5, 1)) +
   theme(strip.text=element_text(size=6, margin=ggplot2::margin(0,0,0,0,unit="cm"))))
```

```{r}
pdf("../plots/ROCs_for_DR_pred.pdf", width=4.5, height=1.5)
DR.pred.roc.curves.cv.strat.by.cage
dev.off()
```

### Feature importance

Extracting feature importance requires a different function.

```{r}
get_feat_imp_for_DR_pred_per_fold <- function(this.annot.df, heldout.cages.vec, tax.feats) {
  
  this.test.ids <- this.annot.df %>% 
    dplyr::filter(Cage %in% heldout.cages.vec) %>% 
    pull(stool.ID)
  this.train.ids <- setdiff(this.annot.df$stool.ID, this.test.ids)
  
  this.train.df <- this.annot.df %>% 
    dplyr::filter(stool.ID %in% this.train.ids) %>% 
    dplyr::select(DR, all_of(tax.feats))
  this.test.df <- this.annot.df %>% 
    dplyr::filter(stool.ID %in% this.test.ids) %>% 
    dplyr::select(DR, all_of(tax.feats))
  
  this.rf.res <- randomForest(
    DR ~ .,
    data = this.train.df,
    importance = T)
  
  # extract importance
  this.imp.df <- data.frame(this.rf.res$importance)

  return(this.imp.df)
  
}
```

```{r}
get_feat_imp_for_DR_pred_per_age <- function(this.age, this.annot.df, tax.feats) {
  
  # subset to this age
  this.age.annot.df <- this.annot.df %>% 
    dplyr::filter(age.approx.months == this.age)
  
  # perform cross-validation, stratifying by cage
  # return which cages are held out in each fold
  this.age.list.of.heldout.cages.per.fold <- get_list_of_heldout_cages_per_fold(this.age.annot.df)
  
  # get feature importance df for each fold
  this.age.feat.imp.df.cv.strat.by.cage <- foreach(
    this.fold.ii = seq(length(this.age.list.of.heldout.cages.per.fold)),
    .combine="rbind") %do% {
      
      feat.imp.df <- get_feat_imp_for_DR_pred_per_fold(
        this.age.annot.df, 
        this.age.list.of.heldout.cages.per.fold[[this.fold.ii]],
        tax.feats)
      
      # add fold and age
      feat.imp.df$fold <- this.fold.ii
      feat.imp.df$age <- this.age
      
      # move rownames to new column
      feat.imp.df <- rownames_to_column(feat.imp.df, "feature")
      
      return(feat.imp.df)
      
    }
  
}
```

```{r}
set.seed(456)
DR.pred.feat.imp.5mo <- get_feat_imp_for_DR_pred_per_age(5, genus.annot.df, tax.feats)
DR.pred.feat.imp.10mo <- get_feat_imp_for_DR_pred_per_age(10, genus.annot.df, tax.feats)
DR.pred.feat.imp.16mo <- get_feat_imp_for_DR_pred_per_age(16, genus.annot.df, tax.feats)
DR.pred.feat.imp.22mo <- get_feat_imp_for_DR_pred_per_age(22, genus.annot.df, tax.feats)
DR.pred.feat.imp.28mo <- get_feat_imp_for_DR_pred_per_age(28, genus.annot.df, tax.feats)

DR.pred.feat.imp.df <- rbind(
  DR.pred.feat.imp.5mo,
  DR.pred.feat.imp.10mo,
  DR.pred.feat.imp.16mo,
  DR.pred.feat.imp.22mo,
  DR.pred.feat.imp.28mo)

table(DR.pred.feat.imp.df$age)
```

Determine which features are most important, across post-randomization ages.

```{r}
DR.pred.feat.imp.summarised.df <- DR.pred.feat.imp.df %>% 
  dplyr::filter(age >= 10) %>% 
  group_by(feature) %>% 
  summarise(MeanMeanDecreaseAccuracy = mean(MeanDecreaseAccuracy), .groups="drop") %>% 
  arrange(desc(MeanMeanDecreaseAccuracy))

DR.pred.top.10.most.imp.feats <- DR.pred.feat.imp.summarised.df %>% 
  slice_max(MeanMeanDecreaseAccuracy, n=10) %>% 
  pull(feature)

DR.pred.top.20.most.imp.feats <- DR.pred.feat.imp.summarised.df %>% 
  slice_max(MeanMeanDecreaseAccuracy, n=20) %>% 
  pull(feature)
```

Plot collapsing across age. 

```{r}
(DR.pred.feat.imp.p <- DR.pred.feat.imp.df %>% 
   dplyr::filter(age >= 10) %>% 
   dplyr::filter(feature %in% DR.pred.top.10.most.imp.feats) %>% 
   ggplot(aes(x=MeanDecreaseAccuracy, y=reorder(feature, MeanDecreaseAccuracy))) +
   stat_summary(fun="mean", geom="col", fill=diet.color) +
   geom_jitter(height=0.1, shape=16) +
   labs(x="Mean decrease in accuracy", y="Genus",
        title="10 most important genera for binary DR prediction"))
```

```{r}
pdf("../plots/binary_DR_pred_top_10_most_imp_feats.pdf", height=2.5, width=3)
DR.pred.feat.imp.p
dev.off()
```

## Pathways

Convert Diet to DR column.

```{r}
pathway.log2tpm.annot.df <- pathway.log2tpm.annot.df %>% 
  mutate(DR = factor(case_when(
    Diet == "AL" ~ "N",
    TRUE ~ "Y")))

table(pathway.log2tpm.annot.df$DR)
```

Perform prediction within each age. Return ROC coordinates for each fold.

```{r}
set.seed(456)
pathway.DR.pred.roc.coords.5mo <- get_roc_coord_for_DR_pred_per_age(5, pathway.log2tpm.annot.df, fxn.feats)
pathway.DR.pred.roc.coords.10mo <- get_roc_coord_for_DR_pred_per_age(10, pathway.log2tpm.annot.df, fxn.feats)
pathway.DR.pred.roc.coords.16mo <- get_roc_coord_for_DR_pred_per_age(16, pathway.log2tpm.annot.df, fxn.feats)
pathway.DR.pred.roc.coords.22mo <- get_roc_coord_for_DR_pred_per_age(22, pathway.log2tpm.annot.df, fxn.feats)
pathway.DR.pred.roc.coords.28mo <- get_roc_coord_for_DR_pred_per_age(28, pathway.log2tpm.annot.df, fxn.feats)

pathway.DR.pred.roc.coord.df.cv.strat.by.cage <- rbind(
  pathway.DR.pred.roc.coords.5mo,
  pathway.DR.pred.roc.coords.10mo,
  pathway.DR.pred.roc.coords.16mo,
  pathway.DR.pred.roc.coords.22mo,
  pathway.DR.pred.roc.coords.28mo)

table(pathway.DR.pred.roc.coord.df.cv.strat.by.cage$age)
```

Create one minus specificity column because that's what we actually plot.

```{r}
pathway.DR.pred.roc.coord.df.cv.strat.by.cage <- pathway.DR.pred.roc.coord.df.cv.strat.by.cage %>%
  mutate(one.minus.spec = 1-specificity)
```

Create interpolated ROCs to make it easy to create a mean ROC.

```{r}
# takes ~15 sec
pathway.DR.pred.roc.plot.df.cv.strat.by.cage <- pathway.DR.pred.roc.coord.df.cv.strat.by.cage %>% 
  group_by(age, fold, AUC) %>% 
  group_modify(~ create_roc_plot_df(.x)) %>% 
  ungroup()
```

Calculate mean AUC per age.

```{r}
pathway.DR.pred.mean.AUC.per.age.cv.strat.by.cage <- pathway.DR.pred.roc.plot.df.cv.strat.by.cage %>% 
  distinct(age, fold, AUC) %>%
  group_by(age) %>% 
  summarise(mean.AUC = mean(AUC), .groups="drop")
```

Create mean ROC.

```{r}
pathway.DR.pred.mean.roc.plot.df.cv.strat.by.cage <- pathway.DR.pred.roc.plot.df.cv.strat.by.cage %>% 
  
  group_by(age, x) %>% 
  summarise(y = mean(y), .groups="drop") %>% 
  
  # add mean AUC (helpful for plotting)
  left_join(pathway.DR.pred.mean.AUC.per.age.cv.strat.by.cage, by="age") %>% 
  
  # make it pretty 
  mutate(mean.AUC.str = sprintf("Mean AUC = %.2f", mean.AUC))
```

Plot.

```{r}
(pathway.DR.pred.roc.curves.cv.strat.by.cage <- pathway.DR.pred.roc.plot.df.cv.strat.by.cage %>% 
   
   # add mean AUC per age
   left_join(pathway.DR.pred.mean.AUC.per.age.cv.strat.by.cage, by="age") %>% 
   
   # make it look pretty
   mutate(mean.AUC.str = sprintf("Mean AUC = %.2f", mean.AUC)) %>% 
   
   arrange(fold) %>% 
   
   ggplot(aes(x=x, y=y, group=fold)) +
   geom_abline(slope=1, lty=2) +
   geom_path(alpha=0.3) +
   geom_path(aes(group=NULL), linewidth=1, color=diet.color,
             data=pathway.DR.pred.mean.roc.plot.df.cv.strat.by.cage) +
   theme_classic(base_size=8) +
   labs(x="1 - Specificity", y="Sensitivity") +
   facet_wrap(~ age + mean.AUC.str, nrow=1) +
   scale_x_continuous(breaks=c(0, 0.5, 1)) +
   theme(strip.text=element_text(size=6, margin=ggplot2::margin(0,0,0,0,unit="cm"))))
```

```{r}
pdf("../plots/ROCs_for_DR_pred_pathways.pdf", width=4.5, height=1.5)
pathway.DR.pred.roc.curves.cv.strat.by.cage
dev.off()
```

### Feature importance

```{r}
set.seed(456)
DR.pred.path.imp.5mo <- get_feat_imp_for_DR_pred_per_age(5, pathway.log2tpm.annot.df, fxn.feats)
DR.pred.path.imp.10mo <- get_feat_imp_for_DR_pred_per_age(10, pathway.log2tpm.annot.df, fxn.feats)
DR.pred.path.imp.16mo <- get_feat_imp_for_DR_pred_per_age(16, pathway.log2tpm.annot.df, fxn.feats)
DR.pred.path.imp.22mo <- get_feat_imp_for_DR_pred_per_age(22, pathway.log2tpm.annot.df, fxn.feats)
DR.pred.path.imp.28mo <- get_feat_imp_for_DR_pred_per_age(28, pathway.log2tpm.annot.df, fxn.feats)

DR.pred.path.imp.df <- rbind(
  DR.pred.path.imp.5mo,
  DR.pred.path.imp.10mo,
  DR.pred.path.imp.16mo,
  DR.pred.path.imp.22mo,
  DR.pred.path.imp.28mo)

table(DR.pred.path.imp.df$age)
```

Determine which features are most important, across post-randomization ages.

```{r}
DR.pred.path.imp.summarised.df <- DR.pred.path.imp.df %>% 
  dplyr::filter(age >= 10) %>% 
  group_by(feature) %>% 
  summarise(MeanMeanDecreaseAccuracy = mean(MeanDecreaseAccuracy), .groups="drop") %>% 
  arrange(desc(MeanMeanDecreaseAccuracy))

DR.pred.top.10.most.imp.paths <- DR.pred.path.imp.summarised.df %>% 
  slice_max(MeanMeanDecreaseAccuracy, n=10) %>% 
  pull(feature)
```

Plot collapsing across age. 

```{r}
(DR.pred.path.imp.p <- DR.pred.path.imp.df %>% 
   dplyr::filter(age >= 10) %>% 
   dplyr::filter(feature %in% DR.pred.top.10.most.imp.paths) %>% 
   
   # use human-readable pathway name, but make the label small
   merge(pathway.names.df, by.x="feature", by.y="short.clean") %>% 
   
   ggplot(aes(x=MeanDecreaseAccuracy, y=reorder(after.colon.short.w.ID, MeanDecreaseAccuracy))) +
   stat_summary(fun="mean", geom="col", fill=diet.color) +
   geom_jitter(height=0.1, shape=16) +
   labs(x="Mean decrease in accuracy", y="Pathway",
        title="10 most important pathways for binary DR prediction") +
   theme(axis.text.y = element_text(size=4)))
```

```{r}
pdf("../plots/binary_DR_pred_top_10_most_imp_paths.pdf", height=2.5, width=3)
DR.pred.path.imp.p
dev.off()
```

# Predict diet

## Genera

Use cross-validation to get a prediction per cross-validation fold. Stratify by cage.

```{r}
run_rf_diet_one_age_strat_by_cage <- function(this.age.approx.month) {
  
  cat(this.age.approx.month, "\n")
  
  this.age.annot.df <- genus.annot.df %>% 
    dplyr::filter(age.approx.months == this.age.approx.month)
  
  colnames(this.age.annot.df)
  
  # extract vector of cages for stratification & remove cage
  this.cage.vec <- this.age.annot.df$Cage
  this.age.data.df <- this.age.annot.df %>%
    dplyr::select(Diet, all_of(tax.feats))
  
  # use groupKFold to make sure that cages aren't split between training and testing
  these.folds <- groupKFold(this.cage.vec, k=10)
  this.train.control <- trainControl(
    index=these.folds, method="cv",
    savePredictions="final")
  
  # perform cross-validation to get predictions on validation sets
  this.diet.rf.strat.by.cage <- train(
    Diet ~ .,
    data = this.age.data.df, 
    method = 'rf', 
    
    # no need to do parameter search, use rf default for classification
    tuneGrid = data.frame(.mtry = floor(sqrt(length(tax.feats)))),
    trControl = this.train.control)
  
  # return predictions on validation sets
  return(this.diet.rf.strat.by.cage$pred %>% 
           mutate(age.months = this.age.approx.month))
}
```

```{r}
all.rf.diet.pred.res <- sapply(
  c(5, 10, 16, 22, 28),
  run_rf_diet_one_age_strat_by_cage
)
```

```{r}
all.rf.diet.pred.df <- all.rf.diet.pred.res %>% 
  t() %>% data.frame() %>% 
  unnest(everything()) %>% 
  mutate(is.correct = (pred == obs))
```

Calculate accuracy on each fold.

```{r}
all.rf.diet.accuracy.df <- all.rf.diet.pred.df %>% 
  group_by(age.months, Resample) %>% 
  summarise(accuracy = sum(is.correct) / n(), .groups="drop")
```

Add t-test p-value (null hypothesis is that accuracy is *greater* than 20%).

```{r}
all.rf.diet.t.test.df <- all.rf.diet.accuracy.df %>% 
  dplyr::filter(age.months %in% c(5, 10, 16, 22, 28)) %>% 
  mutate(accuracy.minus.20 = accuracy - 0.2) %>% 
  group_by(age.months) %>% 
  summarise(t.test.pval = t.test(accuracy.minus.20, alternative="greater")$p.value, .groups="drop") %>% 
  mutate(t.test.pval.symbol = case_when(
    t.test.pval < 0.0001 ~ "****",
    t.test.pval < 0.001 ~ "***",
    t.test.pval < 0.01 ~ "**",
    t.test.pval < 0.05 ~ "*",
    TRUE ~ "ns"))
```

```{r}
(diet.pred.v.age.p <- all.rf.diet.accuracy.df %>% 
   dplyr::filter(age.months %in% c(5, 10, 16, 22, 28)) %>% 
   mutate(is.post.randomiz = (age.months > 5)) %>% 
   ggplot(aes(x=factor(age.months), y=100*accuracy, fill=is.post.randomiz)) +
   stat_summary(fun="mean", geom="col") +
   geom_point(size=0.5, shape=16) +
   geom_text(aes(y=85, label=t.test.pval.symbol, fill=NULL),
             data=all.rf.diet.t.test.df) +
   geom_hline(yintercept=20, lty=2) +
   labs(x="Age (months)", y="Accuracy", 
        title="Prediction of dietary group, genera") +
   scale_fill_manual(values=c(`FALSE`="gray80", `TRUE`=diet.color)) +
   ylim(0, 90) +
   theme_classic(base_size=8) +
   theme(legend.position="none"))
```

```{r}
pdf("../plots/diet_prediction_accuracy_v_age_genera.pdf", width=2, height=2)
diet.pred.v.age.p
dev.off()
```

### Plot accuracy versus diet

```{r}
no.5mo.rf.diet.pred.df <- all.rf.diet.pred.df %>% 
  dplyr::filter(age.months != 5)
```

```{r}
(diet.pred.v.diet.p <- no.5mo.rf.diet.pred.df %>% 
   group_by(obs) %>% 
   summarise(accuracy = sum(is.correct) / n(), .groups="drop") %>% 
   mutate(diet = factor(obs, levels = c("AL", "1D", "2D", "20", "40"))) %>% 
   ggplot(aes(x=diet, y=100*accuracy, fill=diet)) +
   geom_col() +
   scale_fill_manual(values=diet.palette) +
   ylim(0, 80) +
   theme_classic(base_size=8) +
   theme(legend.position="none") +
   labs(x="Dietary group", y="Accuracy", 
        title="Post-randomization, genera"))
```

```{r}
pdf("../plots/diet_prediction_accuracy_v_diet_post_randomiz.pdf", width=2, height=2)
diet.pred.v.diet.p
dev.off()
```

## Pathways

```{r}
run_rf_diet_one_age_pathway_strat_by_cage <- function(this.age.approx.month) {
  
  cat(this.age.approx.month, "\n")
  
  # subset to this age
  this.age.pathway.annot.df <- pathway.log2tpm.annot.df %>% 
    dplyr::filter(age.approx.months == this.age.approx.month)
  
  # extract vector of cages for stratification
  this.cage.vec <- this.age.pathway.annot.df$Cage
  
  # keep pathways and Diet
  this.age.pathway.data.df <- this.age.pathway.annot.df %>% 
    dplyr::select(Diet, all_of(fxn.feats))
  
  # use groupKFold to make sure that cages aren't split between training and testing
  these.pathway.folds <- groupKFold(this.cage.vec, k=10)
  this.pathway.train.control <- trainControl(
    index=these.pathway.folds, method="cv",
    savePredictions="final")
  
  # perform cross-validation to get predictions on validation sets
  this.diet.pathway.rf.strat.by.cage <- train(
    Diet ~ .,
    data = this.age.pathway.data.df, 
    method = 'rf', 
    
    # no need to do parameter search, use rf default for classification
    tuneGrid = data.frame(.mtry = floor(sqrt(length(fxn.feats)))),
    trControl = this.pathway.train.control)
  
  # return predictions on validation sets
  return(this.diet.pathway.rf.strat.by.cage$pred %>% 
           mutate(age.months = this.age.approx.month))
}
```

```{r}
all.rf.diet.pathway.pred.res <- sapply(
  c(5, 10, 16, 22, 28),
  run_rf_diet_one_age_pathway_strat_by_cage
)
```

```{r}
all.rf.diet.pathway.pred.df <- all.rf.diet.pathway.pred.res %>% 
  t() %>% data.frame() %>% 
  unnest(everything()) %>% 
  mutate(is.correct = (pred == obs))
```

Calculate accuracy on each fold.

```{r}
all.rf.diet.pathway.accuracy.df <- all.rf.diet.pathway.pred.df %>% 
  group_by(age.months, Resample) %>% 
  summarise(accuracy = sum(is.correct) / n(), .groups="drop")
```

Add t-test p-value.

```{r}
all.rf.diet.pathway.t.test.df <- all.rf.diet.pathway.accuracy.df %>% 
  dplyr::filter(age.months %in% c(5, 10, 16, 22, 28)) %>% 
  mutate(accuracy.minus.20 = accuracy - 0.2) %>% 
  group_by(age.months) %>% 
  summarise(t.test.pval = t.test(accuracy.minus.20, alternative="greater")$p.value, .groups="drop") %>% 
  mutate(t.test.pval.symbol = case_when(
    t.test.pval < 0.0001 ~ "****",
    t.test.pval < 0.001 ~ "***",
    t.test.pval < 0.01 ~ "**",
    t.test.pval < 0.05 ~ "*",
    TRUE ~ "ns"))
```

```{r}
(diet.pred.v.age.pathway.p <- all.rf.diet.pathway.accuracy.df %>% 
   dplyr::filter(age.months %in% c(5, 10, 16, 22, 28)) %>% 
   mutate(is.post.randomiz = (age.months > 5)) %>% 
   ggplot(aes(x=factor(age.months), y=100*accuracy, fill=is.post.randomiz)) +
   stat_summary(fun="mean", geom="col") +
   geom_point(size=0.5, shape=16) +
   geom_text(aes(y=85, label=t.test.pval.symbol, fill=NULL),
             data=all.rf.diet.pathway.t.test.df) +
   geom_hline(yintercept=20, lty=2) +
   labs(x="Age (months)", y="Accuracy", 
        title="Prediction of dietary group, pathways") +
   scale_fill_manual(values=c(`FALSE`="gray80", `TRUE`=diet.color)) +
   ylim(0, 90) +
   theme_classic(base_size=8) +
   theme(legend.position="none"))
```

```{r}
pdf("../plots/diet_prediction_accuracy_v_age_pathway.pdf", width=2, height=2)
diet.pred.v.age.pathway.p
dev.off()
```

### Plot accuracy versus diet

```{r}
no.5mo.rf.diet.pathway.pred.df <- all.rf.diet.pathway.pred.df %>% 
  dplyr::filter(age.months != 5)
```

```{r}
(diet.pathway.pred.v.diet.p <- no.5mo.rf.diet.pathway.pred.df %>% 
   group_by(obs) %>% 
   summarise(accuracy = sum(is.correct) / n(), .groups="drop") %>% 
   mutate(diet = factor(obs, levels = c("AL", "1D", "2D", "20", "40"))) %>% 
   ggplot(aes(x=diet, y=100*accuracy, fill=diet)) +
   geom_col() +
   scale_fill_manual(values=diet.palette) +
   ylim(0, 80) +
   theme_classic(base_size=8) +
   theme(legend.position="none") +
   labs(x="", y="Accuracy", title="Post-randomization, pathways"))
```

```{r}
pdf("../plots/diet_prediction_accuracy_v_diet_post_randomiz_pathways.pdf", width=2, height=2)
diet.pathway.pred.v.diet.p
dev.off()
```

## Is accuracy better for genera than pathways?

```{r}
t.test(
  all.rf.diet.accuracy.df %>% dplyr::filter(age.months > 5) %>% pull(accuracy),
  all.rf.diet.pathway.accuracy.df %>% dplyr::filter(age.months > 5) %>% pull(accuracy))
```
